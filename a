import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        from fastai.text import *
from fastai import *
import seaborn as sns
import matplotlib.pyplot as plt
df  = pd.read_csv('/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')
df.head()
df.shape
df.dtypes
df.fillna(value='No information',inplace=True)
df.fraudulent.value_counts()
sns.set_style('darkgrid')
plt.figure(1,figsize=(20,8))
sns.countplot(hue=df.fraudulent,x=df.employment_type);
plt.title('Which type of jobs have more fraudulent postings');
plt.figure(1,figsize=(20,12))
sns.countplot(y=df.function,hue=df.fraudulent);
plt.title('Which type of jobs function have postings');
plt.xlim(0,800)
path = Path('/kaggle/working/')
data_lm = (TextList.from_df(df,path,cols=['company_profile','description','requirements','benefits'])
           # Creating a textlist for lang model df--> dataframe , cols = Columns of df you want to include in language model
                  .split_by_rand_pct(0.2)
           # # will take 20% of text as validation set
                  .label_for_lm()
           # label it according to a language model
                  .databunch(bs=128))
           # batch size you can decrease the batch size if gpu is going out of memory
           data_lm.show_batch(rows=6)
           learn = language_model_learner(data_lm,AWD_LSTM,metrics=[accuracy,Perplexity()],model_dir='/kaggle/working/',drop_mult=0.3).to_fp16()
           learn.lr_find()
learn.recorder.plot()
import gc
gc.collect()
learn.fit_one_cycle(3, 1e-2 , moms = (0.8,0.7) )
learn.save_encoder('ftenc1')
learn = None
gc.collect()
df.columns
df.head(2)
df0 = df[df['fraudulent']==0][:1400].copy()
df1 = df[df['fraudulent']==1].copy()
train = pd.concat([df0,df1])
train.shape
train.head(2)
label_cols = ['department','employment_type','required_experience','industry','function','required_education','title','company_profile','description','requirements','benefits']
data_cls = (TextList.from_df(train,path,cols=label_cols,vocab=data_lm.vocab)
            # Creating a textlist for lang model df--> dataframe , cols = Columns of df you want to include in classifier model , vocab=we will use same vacab we use to create a language model
                    .split_by_rand_pct(0.2,seed=64)
            #   will take 20% of text as validation set
                    .label_from_df(cols='fraudulent')
            # label the classifier from dataframe cols= target columns name
                    .databunch(bs=128))
            # creates a databunch
            data_cls.show_batch(rows=6)
            clf = None
gc.collect()
fb = FBeta()
fb.average = 'macro'
clf = text_classifier_learner(data_cls,AWD_LSTM,metrics=[accuracy,fb],drop_mult=0.3).to_fp16()
clf.load_encoder('/kaggle/working/ftenc1');
gc.collect()
clf.lr_find()
clf.recorder.plot()
